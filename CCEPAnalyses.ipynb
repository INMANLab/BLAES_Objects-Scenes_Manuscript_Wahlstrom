{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCEP Analyses\n",
    "\n",
    "Load in preprocessed data (created in `CCEPPrepro.ipynb`) and performs X analyses.\n",
    "\n",
    "\n",
    "---\n",
    "> Justin Campbell & Krista Wahlstrom  \n",
    "> Version: 3/05/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import mne\n",
    "import sys\n",
    "import glob\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import iirnotch, lfilter, sosfilt, butter\n",
    "\n",
    "# Notebook settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session to analyze\n",
    "pID = 'UIC202208'\n",
    "stimPair = 'RAMG2-RAMG3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and find datafiles\n",
    "#rootDir = '/Users/justincampbell/Library/CloudStorage/Box-Box/INMANLab/BCI2000/BLAES Aim 2.1/CCEPs/' # Justin's path\n",
    "rootDir = '/Users/inmanlab/Library/CloudStorage/Box-Box/INMANLab/BCI2000/BLAES Aim 2.1/CCEPs/' #Krista's path\n",
    "\n",
    "datapath = os.path.join(rootDir, 'Data')\n",
    "\n",
    "if pID[0:3] == 'UIC':\n",
    "    fileType = 'Utah'\n",
    "    datapath = os.path.join(datapath, 'Utah_Data')\n",
    "else:\n",
    "    fileType = 'WashU'\n",
    "    datapath = os.path.join(datapath, 'WashU_Data')\n",
    "\n",
    "preproDataPath = os.path.join(datapath, 'Prepro', (pID + '_' + stimPair))\n",
    "savepath = os.path.join(rootDir, 'Results', (pID + '_' + stimPair))\n",
    "\n",
    "# Create results folder if it doesn't exist\n",
    "if not os.path.exists(savepath):\n",
    "    os.mkdir(savepath)\n",
    "\n",
    "try:\n",
    "    # Load preprocessed data\n",
    "    data = np.load(os.path.join(preproDataPath, 'PreproData.npy'))\n",
    "    events = np.load(os.path.join(preproDataPath, 'Events.npy'))\n",
    "    chans = pd.read_csv(os.path.join(preproDataPath, 'ChanLabels.csv'), index_col=0)['Chan'].to_list()\n",
    "    bad_chans = pd.read_csv(os.path.join(preproDataPath, 'DroppedChans.csv'), index_col=0)['Dropped Chans'].to_list()\n",
    "    # Set Fs\n",
    "    if fileType == 'Utah':\n",
    "        fs = 1000\n",
    "    elif fileType == 'WashU':\n",
    "        fs = 2000\n",
    "except:\n",
    "    print('Error loading data')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove Bad Channels\n",
    "Stored in `DroppedChans.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of bad channels in chans\n",
    "bad_chan_inds = [chans.index(chan) for chan in bad_chans]\n",
    "\n",
    "# remove bad channels from data\n",
    "data = np.delete(data, bad_chan_inds, axis=1)\n",
    "\n",
    "# remove bad channels from chans\n",
    "chans = [chan for chan in chans if chan not in bad_chans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trials: 27\n",
      "# Chans: 86\n",
      "Epoch Length: 1.80s\n"
     ]
    }
   ],
   "source": [
    "print('# Trials: %i' % len(events))\n",
    "print('# Chans: %i' % len(chans))\n",
    "print('Epoch Length: %.2fs' % (data.shape[2]/fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Z-Score Post-Stim Response\n",
    "\n",
    "\\begin{equation}\n",
    "Z_{trial} = \\frac{x_{trial} - \\mu_{pre}}{\\sigma_{pre}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate data into pre and post stim\n",
    "midpoint = int(data.shape[2] / 2)\n",
    "preStim = data[:, :, 0:midpoint]\n",
    "postStim = data[:, :, midpoint:]\n",
    "\n",
    "# Define baseline (in pre-stim data)\n",
    "baselineEnd = int(fs / 100)\n",
    "baselineStart = int((data.shape[2] / 2) - baselineEnd - (fs/2))\n",
    "baseline = preStim[:, :, baselineStart:-baselineEnd]\n",
    "\n",
    "# Get mean and SD of baseline (over time)\n",
    "baselineMean = np.mean(baseline, axis=2)\n",
    "baselineSD = np.std(baseline, axis=2)\n",
    "\n",
    "# Normalize data\n",
    "postStimZ = np.zeros(postStim.shape)\n",
    "for trial in range(postStim.shape[0]):\n",
    "    for channel in range(postStim.shape[1]):\n",
    "        postStimZ[trial, channel, :] = (postStim[trial, channel, :] - baselineMean[trial, channel]) / baselineSD[trial, channel]\n",
    "        \n",
    "# Get trial-averaged responses\n",
    "postStimAvg = np.mean(postStimZ, axis=0)\n",
    "\n",
    "# Calculate SEM\n",
    "postStimSEM = np.std(postStimZ, axis=0) / np.sqrt(postStimZ.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Amplitude-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define windows of interest\n",
    "N1Window = [10, 50]\n",
    "N2Window = [50, 400]\n",
    "N1Start = int(N1Window[0] * fs / 1000) #Convert milliseconds to samples\n",
    "N1End = int(N1Window[1] * fs / 1000)\n",
    "N2Start = int(N2Window[0] * fs / 1000)\n",
    "N2End = int(N2Window[1] * fs / 1000)\n",
    "ccepStart = int(10 * fs / 1000)\n",
    "midAmpEnd = int(100 * fs / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCCEP(chanIdx, showFeatures = True, showPlot = False, export = False):\n",
    "    '''\n",
    "    This function plots the CCEP waveform for a given channel index. It also calculates the following features:\n",
    "    - N1: The peak amplitude between 10 and 50ms\n",
    "    - N2: The peak amplitude between 50 and 400ms\n",
    "    - Overall Peak: The overall peak amplitude in the full window\n",
    "    - Mid Amp: The peak amplitude between 10 and 100ms\n",
    "    - AUC: The area under the curve of the full window\n",
    "    \n",
    "    Inputs:\n",
    "    - chanIdx: The index of the channel to plot\n",
    "    - showFeatures: Whether or not to display the features on the plot (default = True)\n",
    "    - export: Whether or not to export the plot (default = False)\n",
    "    \n",
    "    Outputs:\n",
    "    - Plot of the CCEP waveform with features (if showFeatures = True)\n",
    "    '''\n",
    "\n",
    "    # Get features\n",
    "    N1Idx = np.argmax(np.abs(postStimAvg[chanIdx, N1Start:N1End])) + N1Start # Find the index of max value between 10 and 50ms\n",
    "    N1Val = np.abs(postStimAvg[chanIdx, N1Idx])\n",
    "    N1Lat = np.round((N1Idx * 1000) / fs, 2) #Convert samples to milliseconds\n",
    "\n",
    "    N2Idx = np.argmax(np.abs(postStimAvg[chanIdx, N2Start:N2End])) + N2Start # Find the index of max value between 50 and 400ms\n",
    "    N2Val = np.abs(postStimAvg[chanIdx, N2Idx])\n",
    "    N2Lat = np.round((N2Idx * 1000) / fs, 2)\n",
    "\n",
    "    overallPeakIdx = np.argmax(np.abs(postStimAvg[chanIdx, ccepStart:])) + ccepStart # Find the overall peak in full window\n",
    "    overallPeakVal = np.abs(postStimAvg[chanIdx, overallPeakIdx])\n",
    "    overallPeakLat = np.round((overallPeakIdx * 1000) / fs, 2)\n",
    "\n",
    "    midAmpIdx = np.argmax(np.abs(postStimAvg[chanIdx, ccepStart:midAmpEnd])) + ccepStart # Find the peak between 10 and 100ms\n",
    "    midAmpVal = np.abs(postStimAvg[chanIdx, midAmpIdx])\n",
    "    midAmpLat = np.round((midAmpIdx * 1000) / fs, 2)\n",
    "\n",
    "    ccepAUCVal = np.trapz(np.abs(postStimAvg[chanIdx, ccepStart:])) # Calculate AUC\n",
    "\n",
    "    # Create time vector\n",
    "    time = np.arange(0, postStimAvg.shape[1])\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    plt.plot(time, postStimAvg[chanIdx, :], color = 'blue', zorder = 10, lw = 2)\n",
    "    plt.fill_between(time, postStimAvg[chanIdx, :] + postStimSEM[chanIdx, :], postStimAvg[chanIdx, :] - postStimSEM[chanIdx, :], color = 'blue', alpha = 0.125)\n",
    "\n",
    "    if showFeatures:\n",
    "        plt.axvline(N1Idx, color='r', lw = 2, linestyle = ':', label = 'N1: ' + str(round(N1Val, 2)) + ' (' + str(N1Lat) + 'ms)', zorder = 20)\n",
    "        plt.axvline(N2Idx, color='purple', lw = 2, linestyle = ':', label = 'N2: ' + str(round(N2Val, 2)) + ' (' + str(N2Lat) + 'ms)', zorder = 20)\n",
    "        plt.axvline(overallPeakIdx, color='g', lw = 2, linestyle = ':', label = 'Overall: ' + str(round(overallPeakVal, 2)) + ' (' + str(overallPeakLat) + 'ms)', zorder = 20)\n",
    "        plt.axvline(midAmpIdx, color='orange', lw = 2, linestyle = ':', label = 'Mid Amp: ' + str(round(midAmpVal, 2)) + ' (' + str(midAmpLat) + 'ms)', zorder = 20)\n",
    "        plt.axvline(-1, color='k', lw = 2, linestyle = ':', label = 'AUC: ' + str(round(ccepAUCVal, 2)))\n",
    "\n",
    "    # Figure aesthetics\n",
    "    if showFeatures:\n",
    "        plt.legend(title = 'Features', title_fontsize = 'small', fontsize = 'x-small', bbox_to_anchor=(1.3, 1))\n",
    "    else:\n",
    "        featureStr = 'Features:\\n' + 'N1: ' + str(round(N1Val, 2)) + ' (' + str(N1Lat) + 'ms)' + '\\nN2: ' + str(round(N2Val, 2)) + ' (' + str(N2Lat) + 'ms)' + '\\nOverall: ' + str(round(overallPeakVal, 2)) + ' (' + str(overallPeakLat) + 'ms)' + '\\nMid Amp: ' + str(round(midAmpVal, 2)) + ' (' + str(midAmpLat) + 'ms)' + '\\nAUC: ' + str(round(ccepAUCVal, 2))\n",
    "        plt.text(1.05, .75, featureStr, fontsize = 'x-small', bbox = {'boxstyle': 'round', 'ec': (.5, 0.5, 0.5), 'fc': (1., 1., 1.)}, transform=ax.transAxes)\n",
    "\n",
    "    plt.axvspan(0, 10, color='r', alpha=0.1)\n",
    "    plt.text(1.05, 1.025, pID + '\\n' + stimPair, fontsize= 'x-small', verticalalignment='center', transform=ax.transAxes)\n",
    "    plt.xlim(0, int(900 * fs / 1000)) #Label the x-axis based on samples/sampling rate\n",
    "    plt.xticks(ax.get_xticks(),labels=['0','100','200','300','400','500','600','700','800','900']) #Manually re-label the x-axis tick marks\n",
    "    plt.title(chans[chanIdx])\n",
    "    sns.despine(top=True, right=True)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('Z-Scored (Amplitude)')\n",
    "\n",
    "    # Export\n",
    "    if export:\n",
    "        magDir = os.path.join(savepath, 'Magnitude')\n",
    "        if not os.path.exists(magDir):\n",
    "            os.mkdir(magDir)\n",
    "        plt.savefig(os.path.join(magDir, chans[chanIdx] + '.png'), dpi=1200, bbox_inches='tight')\n",
    "    if showPlot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatureDF(export = False):\n",
    "    '''\n",
    "    This function creates a dataframe of features for all channels in the CCEP data.\n",
    "    \n",
    "    Inputs:\n",
    "    - export: Whether or not to export the dataframe to a CSV file (default = False)\n",
    "    \n",
    "    Outputs:\n",
    "    - featureDF: A dataframe of features for all channels in the CCEP data\n",
    "    '''\n",
    "\n",
    "    holder = []\n",
    "    for chanIdx in range(len(chans)):\n",
    "\n",
    "        # Get features\n",
    "        N1Idx = np.argmax(np.abs(postStimAvg[chanIdx, N1Start:N1End])) + N1Start # Find the index of max value between 10 and 50ms\n",
    "        N1Val = np.abs(postStimAvg[chanIdx, N1Idx])\n",
    "        N1Lat = np.round((N1Idx * 1000) / fs, 2) #Convert samples to milliseconds\n",
    "\n",
    "        N2Idx = np.argmax(np.abs(postStimAvg[chanIdx, N2Start:N2End])) + N2Start # Find the index of max value between 50 and 400ms\n",
    "        N2Val = np.abs(postStimAvg[chanIdx, N2Idx])\n",
    "        N2Lat = np.round((N2Idx * 1000) / fs, 2)\n",
    "\n",
    "        overallPeakIdx = np.argmax(np.abs(postStimAvg[chanIdx, ccepStart:])) + ccepStart # Find the overall peak in full window\n",
    "        overallPeakVal = np.abs(postStimAvg[chanIdx, overallPeakIdx])\n",
    "        overallPeakLat = np.round((overallPeakIdx * 1000) / fs, 2)\n",
    "\n",
    "        midAmpIdx = np.argmax(np.abs(postStimAvg[chanIdx, ccepStart:midAmpEnd])) + ccepStart # Find the peak between 10 and 100ms\n",
    "        midAmpVal = np.abs(postStimAvg[chanIdx, midAmpIdx])\n",
    "        midAmpLat = np.round((midAmpIdx * 1000) / fs, 2)\n",
    "\n",
    "        ccepAUCVal = np.trapz(np.abs(postStimAvg[chanIdx, ccepStart:])) # Calculate AUC\n",
    "\n",
    "        featureDF = pd.DataFrame({'N1': [N1Val], 'N1_Lat': [N1Lat], 'N2': [N2Val], 'N2_Lat': N2Lat, 'Overall Peak': [overallPeakVal], 'Overall Peak_Lat': overallPeakLat, 'Mid Amp': [midAmpVal], 'Mid Amp_Lat': midAmpLat, 'AUC': [ccepAUCVal], 'Chan': [chans[chanIdx]], 'pID': [pID], 'StimPair': [stimPair]})\n",
    "        \n",
    "        holder.append(featureDF)\n",
    "        \n",
    "    featureDF = pd.concat(holder, axis=0)\n",
    "    featureDF.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if export:\n",
    "        magDir = os.path.join(savepath, 'Magnitude')\n",
    "        if not os.path.exists(magDir):\n",
    "            os.mkdir(magDir)\n",
    "        featureDF.to_csv(os.path.join(magDir, 'FeatureDF.csv'), index=False)\n",
    "        \n",
    "    return featureDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Plot CCEPs & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(chans)):\n",
    "    plotCCEP(i, showFeatures = True, showPlot = False, export = True)\n",
    "    \n",
    "# for single-channel plotting:\n",
    "# chanIdx = 0\n",
    "# plotCCEP(chanIdx, showFeatures = True, showPlot = True, export = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Create `FeatureDF` File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createFeatureDF(export = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Spectral Features\n",
    "- HFA (70 - 150Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
